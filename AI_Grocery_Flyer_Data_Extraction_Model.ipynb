{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AI_Grocery_Flyer_Data_Extraction_Model.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"0zv3j6nKrfP4","executionInfo":{"status":"ok","timestamp":1641649972154,"user_tz":300,"elapsed":6938,"user":{"displayName":"Kanistha Ratana-Rueangsri","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07509906626582739277"}}},"source":["import os\n","import numpy as np\n","import torch\n","import torchvision\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt\n","import operator\n","import io\n","import time\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data.sampler import SubsetRandomSampler\n","import pandas as pd\n","import scipy.signal as sg\n","from pathlib import Path\n","import cv2\n","from google.colab.patches import cv2_imshow\n","from PIL import Image\n","from matplotlib import pyplot as plt \n","import PIL.Image\n","import numpy as np\n","import cv2\n","import cv2 as cv\n","import csv\n","from google.colab.patches import cv2_imshow"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":[""],"metadata":{"id":"hsBuoI165zD3"}},{"cell_type":"code","metadata":{"id":"Ivnb4DoZyORs","outputId":"119bf58b-8f41-4d1f-d744-ce562b27b990","executionInfo":{"status":"ok","timestamp":1641649994004,"user_tz":300,"elapsed":21854,"user":{"displayName":"Kanistha Ratana-Rueangsri","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07509906626582739277"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["!sudo pip install pytesseract\n","!sudo apt install tesseract-ocr\n","!sudo apt install libtesseract-dev\n","!pip install requests fuzzywuzzy pandas pyjstat numpy plotly matplotlib seaborn geopy google folium pandas googlemaps"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytesseract\n","  Downloading pytesseract-0.3.8.tar.gz (14 kB)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from pytesseract) (7.1.2)\n","Building wheels for collected packages: pytesseract\n","  Building wheel for pytesseract (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pytesseract: filename=pytesseract-0.3.8-py2.py3-none-any.whl size=14072 sha256=88f6a36036360650a6281c5399a940e7673a79689572cbcfcaa683739bb8cd84\n","  Stored in directory: /root/.cache/pip/wheels/a4/89/b9/3f11250225d0f90e5454fcc30fd1b7208db226850715aa9ace\n","Successfully built pytesseract\n","Installing collected packages: pytesseract\n","Successfully installed pytesseract-0.3.8\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following additional packages will be installed:\n","  tesseract-ocr-eng tesseract-ocr-osd\n","The following NEW packages will be installed:\n","  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n","0 upgraded, 3 newly installed, 0 to remove and 37 not upgraded.\n","Need to get 4,795 kB of archives.\n","After this operation, 15.8 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-eng all 4.00~git24-0e00fe6-1.2 [1,588 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-osd all 4.00~git24-0e00fe6-1.2 [2,989 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr amd64 4.00~git2288-10f4998a-2 [218 kB]\n","Fetched 4,795 kB in 2s (2,915 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package tesseract-ocr-eng.\n","(Reading database ... 155225 files and directories currently installed.)\n","Preparing to unpack .../tesseract-ocr-eng_4.00~git24-0e00fe6-1.2_all.deb ...\n","Unpacking tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n","Selecting previously unselected package tesseract-ocr-osd.\n","Preparing to unpack .../tesseract-ocr-osd_4.00~git24-0e00fe6-1.2_all.deb ...\n","Unpacking tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n","Selecting previously unselected package tesseract-ocr.\n","Preparing to unpack .../tesseract-ocr_4.00~git2288-10f4998a-2_amd64.deb ...\n","Unpacking tesseract-ocr (4.00~git2288-10f4998a-2) ...\n","Setting up tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n","Setting up tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n","Setting up tesseract-ocr (4.00~git2288-10f4998a-2) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following additional packages will be installed:\n","  libleptonica-dev\n","The following NEW packages will be installed:\n","  libleptonica-dev libtesseract-dev\n","0 upgraded, 2 newly installed, 0 to remove and 37 not upgraded.\n","Need to get 2,755 kB of archives.\n","After this operation, 13.8 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libleptonica-dev amd64 1.75.3-3 [1,308 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libtesseract-dev amd64 4.00~git2288-10f4998a-2 [1,447 kB]\n","Fetched 2,755 kB in 2s (1,735 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 2.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package libleptonica-dev.\n","(Reading database ... 155272 files and directories currently installed.)\n","Preparing to unpack .../libleptonica-dev_1.75.3-3_amd64.deb ...\n","Unpacking libleptonica-dev (1.75.3-3) ...\n","Selecting previously unselected package libtesseract-dev.\n","Preparing to unpack .../libtesseract-dev_4.00~git2288-10f4998a-2_amd64.deb ...\n","Unpacking libtesseract-dev (4.00~git2288-10f4998a-2) ...\n","Setting up libleptonica-dev (1.75.3-3) ...\n","Setting up libtesseract-dev (4.00~git2288-10f4998a-2) ...\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n","Collecting fuzzywuzzy\n","  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n","Collecting pyjstat\n","  Downloading pyjstat-2.2.1.tar.gz (794 kB)\n","\u001b[K     |████████████████████████████████| 794 kB 6.9 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (4.4.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (0.11.2)\n","Requirement already satisfied: geopy in /usr/local/lib/python3.7/dist-packages (1.17.0)\n","Requirement already satisfied: google in /usr/local/lib/python3.7/dist-packages (2.0.3)\n","Requirement already satisfied: folium in /usr/local/lib/python3.7/dist-packages (0.8.3)\n","Collecting googlemaps\n","  Downloading googlemaps-4.5.3.tar.gz (32 kB)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n","Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly) (1.3.3)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.6)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.2)\n","Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.4.1)\n","Requirement already satisfied: geographiclib<2,>=1.49 in /usr/local/lib/python3.7/dist-packages (from geopy) (1.52)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from google) (4.6.3)\n","Requirement already satisfied: branca>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from folium) (0.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from folium) (2.11.3)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->folium) (2.0.1)\n","Building wheels for collected packages: pyjstat, googlemaps\n","  Building wheel for pyjstat (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyjstat: filename=pyjstat-2.2.1-py3-none-any.whl size=19427 sha256=0e3e60e73a7f525468efe65f9e677591da0ae2d93868a0c22290f3dfe9aa3dab\n","  Stored in directory: /root/.cache/pip/wheels/8a/f5/95/0d904a03e1b0f40c8d615e09ab6ab46c66e392391aaa02d407\n","  Building wheel for googlemaps (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for googlemaps: filename=googlemaps-4.5.3-py3-none-any.whl size=38479 sha256=d97edebb7c33176ecf8f8bcc8296db611af958a7672d68e69450f866d57c1d59\n","  Stored in directory: /root/.cache/pip/wheels/fa/1a/1c/cc0b8a1652a3f06aea586b0e4714a81bafed830513969baf92\n","Successfully built pyjstat googlemaps\n","Installing collected packages: pyjstat, googlemaps, fuzzywuzzy\n","Successfully installed fuzzywuzzy-0.18.0 googlemaps-4.5.3 pyjstat-2.2.1\n"]}]},{"cell_type":"code","metadata":{"id":"LudnIS92yQbT","outputId":"b5bb002a-8891-4b1e-ae0a-3dbd4db3932d","executionInfo":{"status":"ok","timestamp":1641649994005,"user_tz":300,"elapsed":18,"user":{"displayName":"Kanistha Ratana-Rueangsri","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07509906626582739277"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["from pytesseract import image_to_string\n","import pytesseract\n","from fuzzywuzzy import fuzz\n","from fuzzywuzzy import process"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n","  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"]}]},{"cell_type":"code","metadata":{"id":"7sclFQWJoEu6","outputId":"59b4c212-20a1-43b3-b172-ea3055259e24","executionInfo":{"status":"ok","timestamp":1641650029090,"user_tz":300,"elapsed":35096,"user":{"displayName":"Kanistha Ratana-Rueangsri","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07509906626582739277"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Github/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BrF8PCHB9if1","executionInfo":{"status":"ok","timestamp":1641650029091,"user_tz":300,"elapsed":9,"user":{"displayName":"Kanistha Ratana-Rueangsri","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07509906626582739277"}},"outputId":"21537fe8-9f5e-4b76-82ee-f0f572ef3a5d"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Github\n"]}]},{"cell_type":"code","source":["#one time run to initialize github repo\n","!git init flyer_ai_model\n","%cd flyer_ai_model/\n","%ls -a"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4_2fUm3M_bhT","executionInfo":{"status":"ok","timestamp":1641650546459,"user_tz":300,"elapsed":457,"user":{"displayName":"Kanistha Ratana-Rueangsri","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07509906626582739277"}},"outputId":"d2dba8de-5791-40ca-89fd-3f1db9257e20"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Initialized empty Git repository in /content/drive/My Drive/Github/flyer_ai_model/.git/\n","/content/drive/My Drive/Github/flyer_ai_model\n","\u001b[0m\u001b[01;34m.git\u001b[0m/\n"]}]},{"cell_type":"code","source":["!git add ."],"metadata":{"id":"F1L_I-N4Apgq","executionInfo":{"status":"ok","timestamp":1641650772224,"user_tz":300,"elapsed":173,"user":{"displayName":"Kanistha Ratana-Rueangsri","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07509906626582739277"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["!git status"],"metadata":{"id":"OnpuxSLAAusI","executionInfo":{"status":"ok","timestamp":1641650782177,"user_tz":300,"elapsed":321,"user":{"displayName":"Kanistha Ratana-Rueangsri","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07509906626582739277"}},"outputId":"7d738836-3f2a-4f9c-be93-24efec80c5b2","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["On branch master\n","\n","No commits yet\n","\n","nothing to commit (create/copy files and use \"git add\" to track)\n"]}]},{"cell_type":"code","metadata":{"id":"hE6QBImUrG8i"},"source":["class ImageFolderWithFileName(datasets.ImageFolder):\n","    \"\"\"Custom dataset that includes image file paths. Extends\n","    torchvision.datasets.ImageFolder\n","    \"\"\"\n","\n","    # override the __getitem__ method. this is the method that dataloader calls\n","    def __getitem__(self, index):\n","        # this is what ImageFolder normally returns \n","        original_tuple = super(ImageFolderWithFileName, self).__getitem__(index)\n","        # the image file path\n","        path = Path(self.imgs[index][0]).name\n","        if path.endswith(\"jpg\") or path.endswith(\"png\"):\n","          if \"_\" not in path:\n","            path = path.split(\".\")[0]\n","        #print('kan', type(original_tuple))\n","        ret_with_name = (original_tuple[:1] + (path,))\n","        return ret_with_name\n","\n","data_dir = \"/content/drive/My Drive/Github/flyer_images/\"\n","test_data = ImageFolderWithFileName(data_dir) # our custom dataset"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kfYywBFEur0s"},"source":["# **Sample Image**"]},{"cell_type":"code","metadata":{"id":"HWYtYAgOrlJJ","outputId":"a75352eb-f812-45a0-ee01-009eb13c8295","executionInfo":{"status":"ok","timestamp":1641649057714,"user_tz":300,"elapsed":11556,"user":{"displayName":"Kanistha Ratana-Rueangsri","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07509906626582739277"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1HOs_OKGp7WMXZHaRT-TWdFoHgRb5juCk"}},"source":["test_data[0][0]"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"1g4u4uoPsS4o","outputId":"383a9adb-a36b-4bf1-984c-11d1102b9919","executionInfo":{"status":"ok","timestamp":1641649057715,"user_tz":300,"elapsed":35,"user":{"displayName":"Kanistha Ratana-Rueangsri","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07509906626582739277"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["test_data[0][1]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'week_10_page_1.jpg'"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"CZrdw-VyvsMx"},"source":["# Main"]},{"cell_type":"code","metadata":{"id":"B-CPg9eLzWiq"},"source":["def textSectionChecker(croppedImage):\n","\n","    #testing\n","    #hsv = cv.cvtColor(croppedImage, cv.COLOR_BGR2HSV)\n","    #lower_black = np.array([0,0,0])\n","    #upper_black = np.array([2,2,2])\n","    #mask = cv2.inRange(hsv, lower_black, upper_black)\n","\n","    #res = cv2.bitwise_and(croppedImage,croppedImage, mask=mask)\n","    imgBlack = croppedImage.copy()\n","    imgBlack = cv.cvtColor(imgBlack, cv.COLOR_BGR2GRAY)\n","    imgBlack[imgBlack > 40] = 255\n","    cv2_imshow(imgBlack)\n","\n","    print('llllllllllll')\n","    #works\n","\n","    imgray = cv.cvtColor(croppedImage, cv.COLOR_BGR2GRAY)\n","    ret,thresh1 = cv2.threshold(imgray, 0, 255,cv2.THRESH_OTSU|cv2.THRESH_BINARY_INV)\n","    rect_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 3))\n","    dilation = cv2.dilate(thresh1, rect_kernel, iterations = 1)\n","    kernel = np.ones((1,1),np.uint8)\n","    dilation2 = cv2.dilate(dilation,kernel,iterations = 1)\n","    cv2_imshow(dilation2)\n","    contours, hierarchy = cv2.findContours(dilation2, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n","    im2 = croppedImage.copy()\n","    textContours = 0\n","    print('-------------------------------')\n","    for cnt in contours:\n","        x, y, w, h = cv2.boundingRect(cnt)\n","        cv2.rectangle(im2, (x, y), (x + w, y + h), (0, 255, 0), 1)\n","        element = im2[y:y+h,x:x+w]\n","        currentImage = Image.fromarray(element)\n","        output = pytesseract.image_to_string(currentImage)\n","        #if empty\n","        if output is None:\n","          continue\n","        print(output)\n","        textContours + 1\n","    cv2_imshow(im2)\n","    print('-------------------------------')\n","    if textContours > 4:\n","      return 1\n","    return 0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W9_QToMlWgjY"},"source":["########this is for product\n","product = []\n","row = 0\n","with open(\"/content/drive/My Drive/Github/product_dictionary.csv\") as csvfile:\n","  reader = csv.reader(csvfile, delimiter= ',')\n","  for row in reader:\n","    if row == 0:\n","      row = 1\n","      continue\n","    product.append(row)\n","\n","#####this is for unit\n","unit = []\n","row = 0\n","with open(\"/content/drive/My Drive/Github/units_dictionary.csv\") as csvfile:\n","  reader = csv.reader(csvfile, delimiter= ',')\n","  for row in reader:\n","    if row == 0:\n","      row = 1\n","      continue\n","    unit.append(row[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EW9wprlPziEV"},"source":["def convertStringToFloat(element):\n","  nu = 0\n","  try:\n","    nu = float(element)\n","  except ValueError:\n","    pass\n","    #print(\"Not a float\")\n","  return(nu)\n","\n","def convertStringToInt(element):\n","  nu = 0\n","  try:\n","    nu = int(element)\n","  except ValueError:\n","    pass\n","    #print(\"Not an int\")\n","  return(nu)\n","\n","#this function returns the data for each list element based off different conditions\n","def analyzeData(name, output):\n","\n","  #status = [\"set\", \"unset\", \"multiplier\"]\n","\n","  status = {\n","      \"unit_promo_price\": \"unset\",\n","      \"uom\": \"unset\",\n","      \"least_unit_for_promo\": \"unset\",\n","      \"save_per_unit\": \"unset\",\n","      \"discount\": \"unset\"\n","  }\n","\n","  unit_promo_price = ''\n","  uom = ''\n","  least_unit_for_promo = 1 # default\n","  save_per_unit = ''\n","  discount = ''\n","  organic = 0 #default not organic\n","\n","  for line in output.splitlines():\n","    #print('--------')\n","    #print(line)\n","    \n","    #if organic ever appears, then organic = 1\n","    if(\"organic\" in line.lower()):\n","      organic = 1\n","\n","    list_of_words = (line.lower()).split()\n","\n","    for item in list_of_words:\n","\n","      if (item.lower()).replace(\".\", \"\") in unit:\n","        uom = (item.lower()).replace(\".\", \"\")\n","        #print(\"unit found\", uom)\n","        status[\"uom\"] = \"set\"\n","\n","    #if any(i in str(line.lower()) for i in unit):\n","    #t = set(unit).intersection(list_of_words)\n","    #if t is not None:\n","    #  print('common unit', t)\n","\n","    #print(line.lower())\n","    #print(list_of_words)\n","    if(\"off\" in list_of_words and status[\"discount\"] == \"unset\"):\n","      word_before = list_of_words[list_of_words.index(\"off\") - 1]\n","      if \"half\" == word_before:\n","        discount = 0.5\n","        status[\"discount\"] = \"set\"\n","      elif \"%\" in word_before:\n","        percent = word_before[0:word_before.index(\"%\")]\n","        if convertStringToInt(percent) != 0:\n","          discount = convertStringToInt(percent)/100\n","          status[\"discount\"] = \"set\"\n","        else:\n","          print(\"unknown percentage\")\n","\n","    #Case 1: save amount\n","    #print(line.lower())\n","    #print(list_of_words)\n","    if(\"save\" in list_of_words):\n","      if(len(list_of_words) <= list_of_words.index(\"save\") + 1):\n","        continue;\n","\n","      next_word = list_of_words[list_of_words.index(\"save\") + 1]\n","      #print(\"save:\", next_word)\n","\n","      if \"/\" in next_word:\n","        save_per_unit = next_word[0:next_word.index(\"/\")]\n","        if \"$\" in save_per_unit:\n","          save_per_unit = convertStringToFloat(save_per_unit[(save_per_unit.index(\"$\") + 1):])\n","        elif \"¢\" in save_per_unit:\n","          save_per_unit = convertStringToFloat(save_per_unit[:save_per_unit.index(\"¢\")])/100\n","        #print(\"float\", save_per_unit)\n","        uom_inner = next_word[(next_word.index(\"/\") + 1):]\n","        if uom_inner.lower() in [\"ib\", \"lb\", \"ib.\", \"lb.\"]:\n","          uom = 'lb'\n","        #if unit_inner.lower() in unit :\n","        else:\n","          uom = uom_inner.lower()\n","        #print(\"unit\", uom)\n","        #else:\n","        #  print(\"unknown unit promo price\")\n","        status['save_per_unit'] = \"set\"\n","        status[\"uom\"] = \"set\"\n","\n","      #save $ on unit\n","      elif \"on\" in list_of_words:\n","        before_on = list_of_words[list_of_words.index(\"on\") - 1]\n","\n","        if \"$\" in before_on:\n","          save_per_unit = convertStringToFloat(before_on[(before_on.index(\"$\") + 1):])\n","          status['save_per_unit'] = \"set\"\n","          #print(\"float\", save_per_unit)\n","        elif \"¢\" in before_on:\n","          save_per_unit = convertStringToFloat(before_on[:before_on.index(\"¢\")])/100\n","          status['save_per_unit'] = \"set\"\n","          #print(\"cent\", save_per_unit)\n","        else:\n","          #print(\"unknown continue\")\n","          continue\n","\n","        if(len(list_of_words)> (list_of_words.index(\"on\") + 1)):\n","          after_on = list_of_words[list_of_words.index(\"on\") + 1]\n","        else:\n","          continue\n","\n","        if convertStringToInt(after_on) != 0:\n","          least_unit_for_promo = convertStringToInt(after_on)\n","          save_per_unit = save_per_unit/least_unit_for_promo\n","          status['least_unit_for_promo'] = \"set\"\n","          #print(\"promo unit\", least_unit_for_promo)\n","\n","      elif \"$\" in next_word:\n","        save_per_unit = convertStringToFloat(next_word[(next_word.index(\"$\") + 1):])\n","        status['save_per_unit'] = \"set\"\n","        #print(\"float\", save_per_unit)\n","      elif \"¢\" in next_word:\n","        save_per_unit = convertStringToInt(next_word[:next_word.index(\"¢\")])/100\n","        status['save_per_unit'] = \"set\"\n","        #print(\"cent\", save_per_unit)\n","      else:\n","        pass\n","        #print(\"unknown save\")\n","    \n","    #CASE 2: not save and price is shown in $\n","    elif(len(list_of_words) == 1 and \"$\" in line.lower()):\n","      price = list_of_words[0]\n","      stringpricelen = len(price[(price.index(\"$\")+1):])\n","      #print('99 test', price[(len(price)-3):])\n","      #assume divide by 1000\n","      if (stringpricelen > 2 and price[(len(price)-3):] == '99'):\n","        unit_promo_price = convertStringToFloat(price[(price.index(\"$\")+1):])/1000\n","      else:\n","        unit_promo_price = convertStringToFloat(price[(price.index(\"$\")+1):])/100\n","      status['unit_promo_price'] = \"set\"\n","      #print(\"cent\", unit_promo_price)\n","    #CASE 3: not save and price is shown in ¢\n","    elif(len(list_of_words) == 1 and \"¢\" in line.lower()):\n","      price = list_of_words[0]\n","      unit_promo_price = convertStringToInt(price[:price.index(\"¢\")])/100\n","      status['unit_promo_price'] = \"set\"\n","      #print(\"cent\", unit_promo_price)\n","\n","  #at the end do some calculations if possible before returning\n","\n","  return unit_promo_price, uom, least_unit_for_promo, save_per_unit, discount, organic"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xJ7HGO1i6Nh8"},"source":["import re"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p42GnI60GJwC","outputId":"c8ac9b39-aadb-444b-912a-1844add11af4","executionInfo":{"status":"ok","timestamp":1641649057717,"user_tz":300,"elapsed":34,"user":{"displayName":"Kanistha Ratana-Rueangsri","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07509906626582739277"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["flyer_name = test_data[0][1]\n","print(flyer_name)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["week_10_page_1.jpg\n"]}]},{"cell_type":"code","metadata":{"id":"C_4_kQyDsqQQ","outputId":"46f50012-976c-47d2-c04c-879a3f71a0d4","colab":{"base_uri":"https://localhost:8080/"}},"source":["flyer_name = test_data[0][1]\n","productDict = []\n","\n","for i in range(len(test_data)):\n","    flyer_name = test_data[i][1]\n","    temp = flyer_name.split(\".\")\n","    print(temp)\n","    flyer_name = temp[0]\n","\n","    #contour each flyer to find sections\n","    image = np.array(test_data[i][0])\n","\n","    imgray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n","    ret,thresh1 = cv2.threshold(imgray, 0, 255,cv2.THRESH_OTSU|cv2.THRESH_BINARY_INV)\n","    rect_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 3))\n","    dilation = cv2.dilate(thresh1, rect_kernel, iterations = 1)\n","\n","    #dilate more\n","    kernel = np.ones((20,20),np.uint8)\n","    dilation2 = cv2.dilate(dilation,kernel,iterations = 1)\n","\n","    #find contour for each section\n","    contours, hierarchy = cv2.findContours(dilation2, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n","    im2 = image.copy()\n","    for cnt in contours:\n","          x, y, w, h = cv2.boundingRect(cnt)\n","          cv2.rectangle(im2, (x, y), (x + w, y + h), (0, 255, 0), 1)\n","    #cv2_imshow(im2)\n","\n","    #save cropped images for flyer\n","    cropped_imgs = {}\n","    #cropped_imgs = []\n","    for cnt in contours:\n","        im3 = image.copy()\n","        x, y, w, h = cv2.boundingRect(cnt)\n","        cropped = im3[y:y+h,x:x+w]\n","        #for overlap, save location in original image\n","        name = str(x) + \"-\" + str(x+w) + \"-\" + str(y) + \"-\" + str(y+h)\n","        #print(name)\n","        cropped_imgs[name] = cropped\n","        #cropped_imgs.append(cropped)\n","\n","    #for key, entry in cropped_imgs.items():\n","    #    cv2_imshow(entry)\n","\n","        \n","###############################################################################\n","\n","    i = 0\n","\n","    for key, element in cropped_imgs.items():\n","        #print(\"Iteration\", i)\n","        #####get the main product name contour text\n","        imgOther = element.copy()\n","        imgBlack = element.copy()\n","        imgBlack = cv.cvtColor(imgBlack, cv.COLOR_BGR2GRAY)\n","        imgBlack[imgBlack > 40] = 255\n","\n","        ret,thresh1 = cv2.threshold(imgBlack, 0, 255,cv2.THRESH_OTSU|cv2.THRESH_BINARY_INV)\n","        #cv2_imshow(thresh1)\n","\n","        kernel = np.ones((6,6), np.uint8) \n","        img_erosion = cv2.erode(thresh1, kernel, iterations=1) \n","        #cv2_imshow(img_erosion) \n","\n","        kernel = np.ones((55,55), np.uint8) \n","        img_dilation = cv2.dilate(img_erosion, kernel, iterations=1) \n","        #cv2_imshow(img_dilation)\n","\n","        #---Finding contours ---\n","        contours, hierarchy = cv2.findContours(img_dilation, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n","\n","        im3 = imgBlack.copy()\n","        name = ''\n","        for cnt in contours:\n","                x, y, w, h = cv2.boundingRect(cnt)\n","                cv2.rectangle(im3, (x, y), (x + w + 8, y + h), (0, 255, 0), 1)\n","                element = im3[y:y+h,x:x+w]\n","                currentImage = Image.fromarray(element)\n","                output = pytesseract.image_to_string(currentImage)\n","                #print('product name =', output)\n","                name = name + '^' + output\n","        name = name.replace(\"^^\", \"\")\n","        name = name.replace(\"^\", \" \")\n","        name = name.replace(\"^\", \"\")\n","        name = name.replace(\"\\n\", \" \")\n","        name = name.replace(\"~\", \"\")\n","        name = name.rstrip()\n","        name = name.lstrip()\n","        current = name.split(\"  \")\n","        name = current[0]\n","        i = i + 1\n","        if (name == '' or name == ' '):\n","          continue\n","\n","        value = process.extract(name, product, limit=1, scorer=fuzz.token_sort_ratio)\n","        name = value[0][0][0]\n","        #print('product name:', name)\n","        #cv2_imshow(im3)\n","        \n","        ####get the rest of the text\n","        #boolTextSection = textSectionChecker(element)\n","        currentImage = Image.fromarray(imgOther)\n","        currentImage = currentImage.convert(\"L\")\n","        output = pytesseract.image_to_string(currentImage)\n","        #print(output)\n","        #print(\"\\n\")\n","        #cv2_imshow(imgOther)\n","\n","        unit_promo_price, uom, least_unit_for_promo, save_per_unit, discount, organic = analyzeData(name, output)\n","\n","        list_element = {'flyer_name': flyer_name,\n","                      'product_name': name,\n","                      'unit_promo_price': unit_promo_price,\n","                      'uom': uom,\n","                      'least_unit_for_promo': least_unit_for_promo,\n","                      'save_per_unit': save_per_unit,\n","                      'discount': discount,\n","                      'organic': organic}\n","\n","        productDict.append(list_element)  \n","        #print(list_element)\n","\n","csv_columns = ['flyer_name', 'product_name', 'unit_promo_price', 'uom', 'least_unit_for_promo', 'save_per_unit', 'discount', 'organic']\n","\n","with open(\"/content/drive/My Drive/Github/results.csv\", 'w') as csvfile:\n","  writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n","  writer.writeheader()\n","  for data in productDict:\n","    writer.writerow(data)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['week_10_page_1', 'jpg']\n","['week_10_page_2', 'jpg']\n","['week_10_page_3', 'jpg']\n","['week_10_page_4', 'jpg']\n","['week_11_page_1', 'jpg']\n","['week_11_page_2', 'jpg']\n","['week_11_page_3', 'jpg']\n","['week_11_page_4', 'jpg']\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '>']\n"]},{"output_type":"stream","name":"stdout","text":["['week_12_page_1', 'jpg']\n","['week_12_page_2', 'jpg']\n","['week_12_page_3', 'jpg']\n","['week_12_page_4', 'jpg']\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '>']\n"]},{"output_type":"stream","name":"stdout","text":["['week_13_page_1', 'jpg']\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '= \f \f']\n"]},{"output_type":"stream","name":"stdout","text":["['week_13_page_2', 'jpg']\n","['week_13_page_3', 'jpg']\n","['week_13_page_4', 'jpg']\n","['week_14_page_1', 'jpg']\n","['week_14_page_2', 'jpg']\n","['week_14_page_3', 'jpg']\n","['week_14_page_4', 'jpg']\n","['week_15_page_1', 'jpg']\n","['week_15_page_2', 'jpg']\n","['week_15_page_3', 'jpg']\n","['week_15_page_4', 'jpg']\n","['week_16_page_1', 'jpg']\n","['week_16_page_2', 'jpg']\n","['week_16_page_3', 'jpg']\n","['week_16_page_4', 'jpg']\n","['week_17_page_1', 'jpg']\n","['week_17_page_2', 'jpg']\n","['week_17_page_3', 'jpg']\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '>']\n"]},{"output_type":"stream","name":"stdout","text":["['week_17_page_4', 'jpg']\n","['week_18_page_1', 'jpg']\n","['week_18_page_2', 'jpg']\n","['week_18_page_3', 'jpg']\n"]}]},{"cell_type":"code","metadata":{"id":"YelZmjJhC5Ke"},"source":[""],"execution_count":null,"outputs":[]}]}